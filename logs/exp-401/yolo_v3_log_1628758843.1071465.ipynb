{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86cb563d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#================================================================\n",
    "# Yolo V-3 by irfanhasib.me@hgmail.com\n",
    "# Inspired by -\n",
    "# GitHub      : https://github.com/pythonlessons/TensorFlow-2.x-YOLOv3\n",
    "#================================================================\n",
    "import os\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['PYTHONHASHSEED']=str(0)\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from multiprocessing import Process, Queue, Pipe\n",
    "import time\n",
    "import shutil\n",
    "import json\n",
    "from tqdm import tqdm,trange\n",
    "import pickle\n",
    "import zlib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28fe938c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from yolo.model import YoloModel, calc_yolo_loss, calc_seg_loss\n",
    "from yolo.decoder import YoloDecodeNetout\n",
    "from yolo.dataset import Dataset\n",
    "from yolo.eval import get_mAP\n",
    "from yolo.utils import Utils\n",
    "from yolo.seg_loader import Seg_Utils\n",
    "from yolo.config import *\n",
    "from yolo.tf import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2448836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_test= False\n",
    "yolo_eval= False\n",
    "seg_test= False\n",
    "sanity_check = False\n",
    "data_gen = False\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c67e5744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time                          : 2021-08-12 18:00:43.089144\n",
      "TRAIN_CHECKPOINTS_FOLDER      : logs/exp-401\n",
      "YOLO_TYPE                     : yolov3\n",
      "YOLO_MODEL                    : LITE\n",
      "YOLO_FRAMEWORK                : tf\n",
      "YOLO_V3_WEIGHTS               : model_data/yolov3.weights\n",
      "YOLO_V4_WEIGHTS               : model_data/yolov4.weights\n",
      "YOLO_V3_TINY_WEIGHTS          : model_data/yolov3-tiny.weights\n",
      "YOLO_V4_TINY_WEIGHTS          : model_data/yolov4-tiny.weights\n",
      "YOLO_TRT_QUANTIZE_MODE        : INT8\n",
      "YOLO_CUSTOM_WEIGHTS           : True\n",
      "YOLO_COCO_CLASSES             : model_data/coco/coco.names\n",
      "YOLO_STRIDES                  : [16, 32, 64]\n",
      "YOLO_IOU_LOSS_THRESH          : 0.5\n",
      "YOLO_ANCHOR_PER_SCALE         : 3\n",
      "YOLO_MAX_BBOX_PER_SCALE       : 100\n",
      "YOLO_INPUT_SIZE               : 256\n",
      "YOLO_ANCHORS                  : [[[10, 14], [23, 27], [37, 58]], [[81, 82], [135, 169], [344, 319]], [[0, 0], [0, 0], [0, 0]]]\n",
      "SEED                          : 0\n",
      "TRAIN_YOLO_TINY               : True\n",
      "TRAIN_MODEL_SCALE             : 1\n",
      "TRAIN_SAVE_BEST_ONLY          : True\n",
      "TRAIN_SAVE_WEIGHTS_EVERY      : 1\n",
      "TRAIN_CLASSES                 : model_data/coco/coco.names\n",
      "TRAIN_ANNOT_PATH              : D:/COCO/annotations_trainval2017/annotations/instances_train2017.txt\n",
      "TRAIN_IMG_PATH                : D:/COCO/train2017/\n",
      "TRAIN_DATA_SAVE_PATH          : D:/COCO/train/\n",
      "TRAIN_LOGDIR                  : log\n",
      "TRAIN_MODEL_PATH              : E:/Deep-Learning-For-Robotics/DeepDetect-aux/logs/exp-401/model_epoch_8_val_det_loss_30.556/weights\n",
      "TRAIN_LOAD_IMAGES_TO_RAM      : False\n",
      "TRAIN_BATCH_SIZE              : 64\n",
      "TRAIN_LR                      : 0.001\n",
      "TRAIN_INPUT_SIZE              : 256\n",
      "TRAIN_DATA_AUG                : False\n",
      "TRAIN_TRANSFER                : True\n",
      "TRAIN_FROM_CHECKPOINT         : False\n",
      "TRAIN_LR_INIT                 : 0.0001\n",
      "TRAIN_LR_END                  : 1e-06\n",
      "TRAIN_WARMUP_EPOCHS           : 2\n",
      "TRAIN_EPOCHS                  : 20\n",
      "TRAIN_USE_SEG                 : False\n",
      "TRAIN_USE_SEG_BIN             : True\n",
      "TRAIN_LOSS_WTS                : [1.0, 0.01]\n",
      "TRAIN_SEG_BG                  : True\n",
      "TRAIN_SEG_SCALE               : 2\n",
      "TRAIN_SEG_SUP_CAT             : False\n",
      "TEST_ANNOT_PATH               : D:/COCO/annotations_trainval2017/annotations/instances_val2017.txt\n",
      "TEST_IMG_PATH                 : D:/COCO/val2017/\n",
      "TEST_DATA_SAVE_PATH           : D:/COCO/test/\n",
      "TEST_BATCH_SIZE               : 4\n",
      "TEST_INPUT_SIZE               : 256\n",
      "TEST_DATA_AUG                 : False\n",
      "TEST_DECTECTED_IMAGE_PATH     : \n",
      "TEST_SCORE_THRESHOLD          : 0.3\n",
      "TEST_IOU_THRESHOLD            : 0.45\n",
      "CLASS_NAMES                   : {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorbike', 4: 'aeroplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic-light', 10: 'fire-hydrant', 11: 'stop-sign', 12: 'parking-meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports-ball', 33: 'kite', 34: 'baseball-bat', 35: 'baseball-glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis-racket', 39: 'bottle', 40: 'wine-glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot-dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'sofa', 58: 'pottedplant', 59: 'bed', 60: 'diningtable', 61: 'toilet', 62: 'tvmonitor', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell-phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy-bear', 78: 'hair-drier', 79: 'toothbrush'}\n",
      "NUM_CLASS                     : 80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if yolo_test == True or yolo_eval== True or seg_test==True or sanity_check== True or debug == True:\n",
    "    save_notebook = False\n",
    "else:\n",
    "    save_notebook = True\n",
    "    \n",
    "if save_notebook == True:\n",
    "    if not os.path.exists(TRAIN_CHECKPOINTS_FOLDER): os.makedirs(TRAIN_CHECKPOINTS_FOLDER)\n",
    "    with open(TRAIN_CHECKPOINTS_FOLDER +'/params.txt','w') as file:\n",
    "        log_str='Time '.ljust(30)+': '+str(datetime.now())+'\\n'\n",
    "        for key in list(params.keys())[:-1]:\n",
    "            if key[:2] != '__':\n",
    "                log_str += key.ljust(30)+': ' + str(params[key])+'\\n'\n",
    "        print(log_str)\n",
    "        file.write(log_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab2eace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System time :  1628758843.1071465\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(1000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 1 seconds\n"
     ]
    }
   ],
   "source": [
    "if save_notebook == True:\n",
    "    curr_time=time.time()\n",
    "    print('System time : ',curr_time)\n",
    "    %autosave 1\n",
    "    time.sleep(3)\n",
    "    \n",
    "    shutil.copy('yolo-v3.ipynb',TRAIN_CHECKPOINTS_FOLDER+'/yolo_v3_log_'+str(curr_time)+'.ipynb')\n",
    "    if not os.path.exists(TRAIN_CHECKPOINTS_FOLDER+'/yolo/'): os.makedirs(TRAIN_CHECKPOINTS_FOLDER+'/yolo/')\n",
    "    files = glob.glob('yolo/*')\n",
    "    for file in files:\n",
    "        try : shutil.copy(file,TRAIN_CHECKPOINTS_FOLDER+'/'+file)\n",
    "        except PermissionError:\n",
    "            print('PermissionError : ',file)\n",
    "    %autosave 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92b5ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if yolo_test == True:\n",
    "    if not os.path.exists(TRAIN_CHECKPOINTS_FOLDER+'/pred_imgs'): os.makedirs(TRAIN_CHECKPOINTS_FOLDER+'/pred_imgs')\n",
    "    #video_path   = \"./IMAGES/test.mp4\"\n",
    "    img_path   = \"D:/COCO/val2017/\"\n",
    "    yolo = YoloModel()\n",
    "    yolo_model=yolo.get_model()\n",
    "    decoder = YoloDecodeNetout()\n",
    "\n",
    "    #decoder.detect_video(yolo_model, video_path, input_size=288, show=True, score_threshold=0.1, iou_threshold=0.2, rectangle_colors='')\n",
    "    decoder.detect_images(yolo_model, img_path, output_path=TRAIN_CHECKPOINTS_FOLDER+'/pred_imgs/',input_size=256, show=True, score_threshold=0.3, iou_threshold=0.5, rectangle_colors='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e1fe95",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if yolo_eval == True:\n",
    "    res_dict=[]\n",
    "    for min_overlap in list(range(50,100,5)):\n",
    "        min_overlap = min_overlap/100\n",
    "        for iou_threshold in [0.1]:#,0.2,0.3,0.3,0.4,0.5]:#[0.1,0.2,0.3,0.4,0.5]:\n",
    "            for score_threshold in [0.0]:#,0.05,0.1,0.2]:#[0.1,0.2,0.3,0.4,0.5]:\n",
    "                yolo = YoloModel()\n",
    "                yolo_model=yolo.get_model()\n",
    "                decoder = YoloDecodeNetout()\n",
    "\n",
    "                testset = Dataset('test')\n",
    "                out=get_mAP(yolo_model, testset, decoder, min_overlap= min_overlap ,score_threshold=score_threshold, iou_threshold=iou_threshold, TEST_INPUT_SIZE=YOLO_INPUT_SIZE)\n",
    "                res_dict+=[[out,min_overlap,score_threshold,iou_threshold]]\n",
    "                print(res_dict)\n",
    "    \n",
    "    with open(TRAIN_CHECKPOINTS_FOLDER+'/scores_0.1_0.0001.pkl','wb') as file:\n",
    "        pickle.dump(res_dict,file)\n",
    "    print(sum([res[0] for res in res_dict])/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33450323",
   "metadata": {},
   "outputs": [],
   "source": [
    "if seg_test == True:\n",
    "    trainset = Dataset('train')\n",
    "    testset = Dataset('test')\n",
    "    \n",
    "    \n",
    "    yolo = YoloModel()\n",
    "    yolo_model=yolo.get_model()\n",
    "        \n",
    "    for image , label in trainset:\n",
    "        break\n",
    "        \n",
    "    out = yolo_model.predict(image)\n",
    "    plt.imshow(label[3][1].max(axis=-1))\n",
    "    plt.show()\n",
    "    plt.imshow(out[2][1][:,:,:len(CLASS_NAMES)].max(axis=-1))\n",
    "    plt.show()\n",
    "\n",
    "    for image , label in testset:\n",
    "        break\n",
    "    out = yolo_model.predict(image)\n",
    "    plt.imshow(label[3][1].max(axis=-1))\n",
    "    plt.show()\n",
    "    plt.imshow(out[2][1][:,:,:len(CLASS_NAMES)].max(axis=-1))\n",
    "    plt.show()\n",
    "    \n",
    "    #plt.imshow(label[3][1])\n",
    "    #plt.show()\n",
    "    #plt.imshow(out[2][0][:,:].max(axis=-1))\n",
    "    #plt.imshow(image[0])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ba66f36",
   "metadata": {},
   "source": [
    "#plt.imshow(label[3][1])\n",
    "#plt.show()\n",
    "for i in range(20):\n",
    "    fig,axes = plt.subplots(nrows=1,ncols=2,figsize=(10,4))\n",
    "    axes[0].imshow(out[3][i][:,:].max(axis=-1))\n",
    "    #plt.show()\n",
    "    axes[1].imshow(image[i])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.05867419755847\n",
    "#12.119057160200935"
   ]
  },
  {
   "cell_type": "raw",
   "id": "42a2f99e",
   "metadata": {},
   "source": [
    "res_dict_50 = [res for res in res_dict if res[1] == 0.50]\n",
    "res_dict_75 = [res for res in res_dict if res[1] == 0.75]\n",
    "res_dict_95 = [res for res in res_dict if res[1] == 0.95]\n",
    "\n",
    "res_dict_50=sorted(res_dict_50,key = lambda x: x[0],reverse=True)\n",
    "res_dict_75=sorted(res_dict_75,key = lambda x: x[0],reverse=True)\n",
    "res_dict_95=sorted(res_dict_95,key = lambda x: x[0],reverse=True)\n",
    "res_dict_50,res_dict_75,res_dict_95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a505ce0",
   "metadata": {},
   "source": [
    "Model=tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=80\n",
    ")\n",
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6109dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sanity_check == True:\n",
    "    trainset = Dataset('train')\n",
    "    testset  = Dataset('test')\n",
    "    for train_img, train_label in trainset:\n",
    "        print('..')\n",
    "        break\n",
    "    for test_img, test_label in testset:\n",
    "        print('...')\n",
    "        break\n",
    "    decoder = YoloDecodeNetout()\n",
    "    pred_bbox = [label[0][0] for label in train_label]#[label_sbbox, label_mbbox, label_lbbox]\n",
    "    \n",
    "    pred_bbox = [np.reshape(x, (-1, np.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = np.concatenate(pred_bbox, axis=0)\n",
    "\n",
    "    bboxes = decoder.decode_boxes(pred_bbox, train_img[0], YOLO_INPUT_SIZE, TEST_SCORE_THRESHOLD)\n",
    "    bboxes = decoder.nms(bboxes, TEST_IOU_THRESHOLD, method='nms')\n",
    "\n",
    "    out=Utils.draw_bbox(train_img[0], bboxes, conf=True,show_label=True, show_confidence = True, Text_colors=(255,255,0), rectangle_colors='', tracking=False)\n",
    "    plt.imshow(train_img[0])\n",
    "    plt.show()\n",
    "    plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183580e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wts_check=False\n",
    "if wts_check== True:\n",
    "    wts = yolo_model.trainable_weights\n",
    "    for i in range(len(wts)):\n",
    "        if len(wts[i].shape) and wts[i].shape[0]==3: \n",
    "            print(wts[i].shape)\n",
    "            _wts = tf.abs(wts[i])\n",
    "            vector = tf.reduce_sum(_wts,axis=[0,1])\n",
    "            norm_rev_vec = 1 - vector/tf.reduce_max(vector)\n",
    "            plt.imshow(norm_rev_vec,cmap='gray')\n",
    "            print(tf.reduce_mean(norm_rev_vec))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3761d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss_dict_obj(dict):\n",
    "        def tf2np(self,val):\n",
    "            if hasattr(val,'numpy'):\n",
    "                val=val.numpy()\n",
    "            else:\n",
    "                if val==None: val=0\n",
    "            return val\n",
    "\n",
    "        def sum_update(self,c_dict):\n",
    "            for key,val in c_dict.items():\n",
    "                    if key in list(self.keys()):\n",
    "                        self[key]+=self.tf2np(c_dict[key])\n",
    "                    else:\n",
    "                        self[key]=self.tf2np(c_dict[key])\n",
    "\n",
    "\n",
    "        def ext_update(self,c_dict,_ext='_ext'):\n",
    "            for key,val in c_dict.items():\n",
    "                     self[_ext+key]=self.tf2np(val)\n",
    "\n",
    "        def divide(self,div_val):\n",
    "            for key,val in self.items():\n",
    "                if type(div_val)==dict or type(div_val)==loss_dict_obj:\n",
    "                    self[key]/=div_val[key]\n",
    "                else:\n",
    "                    self[key]/=div_val\n",
    "\n",
    "        def _sum(self):\n",
    "            total=0\n",
    "            for val in self.values():\n",
    "                total+=val\n",
    "            return total\n",
    "\n",
    "        def copy_keys(self,c_dict,keys):\n",
    "            for key in keys:\n",
    "                self[key]=c_dict[key]\n",
    "\n",
    "        def apply(self,func):\n",
    "            for key in self.keys():\n",
    "                self[key]=self.tf2np(func(self[key]))\n",
    "\n",
    "def save_loss_logs(loss_dict,epoch):\n",
    "    if epoch==0: log_str=','.join(list(loss_dict.keys()))+'\\n'\n",
    "    else : log_str = ''\n",
    "    log_str += ','.join(list(map(str,loss_dict.values())))+'\\n'\n",
    "\n",
    "    with open(os.path.join(TRAIN_CHECKPOINTS_FOLDER,'loss.csv'),'a+') as file:\n",
    "        file.write(log_str)\n",
    "            \n",
    "def save_std_logs(train_loss,all_logs,epoch):\n",
    "    def str_func(x):\n",
    "        return str(x.numpy())\n",
    "    \n",
    "    if epoch==0 : log_str='epoch,'+','.join(list(train_loss.keys()))+'\\n'\n",
    "    else : log_str = ''\n",
    "            \n",
    "    for _ind in range(no_train_batch): \n",
    "        log_str += str(epoch)+','\n",
    "        log_str += ','.join(list(map(str_func,all_logs[_ind])))+'\\n'\n",
    "\n",
    "    with open(os.path.join(TRAIN_CHECKPOINTS_FOLDER,'all_loss.csv'),'a+') as file:\n",
    "        file.write(log_str)\n",
    "        \n",
    "def save_sample_losses(sample_losses,epoch):\n",
    "    \n",
    "    for _lind,loss_name in zip([0,1],['det','seg']):\n",
    "        if TRAIN_LOSS_WTS[_lind]:\n",
    "            if epoch==0 : log_str='epoch,'+','.join(list(map(str,range(TRAIN_BATCH_SIZE))))+'\\n'\n",
    "            else : log_str = ''\n",
    "            for _ind in range(no_train_batch): \n",
    "                log_str += str(epoch)+','\n",
    "                log_str += ','.join(list(map(str,sample_losses[_ind][_lind].numpy())))+'\\n'\n",
    "\n",
    "            with open(os.path.join(TRAIN_CHECKPOINTS_FOLDER,'sample_loss_'+loss_name+'.csv'),'a+') as file:\n",
    "                file.write(log_str)\n",
    "            \n",
    "@tf.function#(experimental_relax_shapes=True)  \n",
    "def train_step(image_data, target,epoch):\n",
    "        conv_layer_ind = [0,3,6,9,12,15,18]\n",
    "        train_loss_dict = loss_dict_obj()\n",
    "        sample_loss_dict= loss_dict_obj()\n",
    "        vec_dict = {ind: 1.0 for ind in conv_layer_ind}\n",
    "        det_loss = seg_loss = kl_coef = 0.0\n",
    "        gradients1 = gradients2 = [None]*len(yolo_model.trainable_variables)\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            pred_result = yolo_model(image_data)\n",
    "            del image_data\n",
    "            \n",
    "            if TRAIN_LOSS_WTS[0]:\n",
    "                grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "                for i in range(grid):\n",
    "                    conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "                    loss_dict, smp_loss_dict, grid_det_loss = calc_yolo_loss(pred, conv, *target[i], i)\n",
    "                    train_loss_dict.sum_update(loss_dict)\n",
    "                    sample_loss_dict.sum_update(smp_loss_dict)\n",
    "                    det_loss += grid_det_loss\n",
    "                gradients1 = tape.gradient(TRAIN_LOSS_WTS[0] * det_loss, yolo_model.trainable_variables)\n",
    "                    \n",
    "            if TRAIN_USE_SEG or TRAIN_USE_SEG_BIN:\n",
    "                seg_pred     = pred_result[2*(grid -1)+2:]\n",
    "                seg_label    = target[3:]\n",
    "                seg_loss_dict, seg_sample_losses, seg_loss = calc_seg_loss(seg_label,seg_pred)\n",
    "                train_loss_dict.update(seg_loss_dict)\n",
    "                sample_loss_dict.update(seg_sample_losses)\n",
    "                \n",
    "                \n",
    "                norm_det_sample_losses = sample_loss_dict['det'] / tf.math.reduce_max(sample_loss_dict['det'])\n",
    "                norm_seg_sample_losses = sample_loss_dict['det'] / tf.math.reduce_max(sample_loss_dict['seg'])\n",
    "                #csim = -tf.keras.losses.CosineSimilarity()(norm_det_sample_losses,norm_seg_sample_losses)\n",
    "                kl = tf.keras.losses.KLDivergence()(norm_det_sample_losses,norm_seg_sample_losses)\n",
    "                kl_coef = tf.clip_by_value(1.0 - kl/100.0, 0.0, 1.0)\n",
    "                train_loss_dict['kl_coef'] = kl_coef#.numpy()\n",
    "                \n",
    "                gradients2 = tape.gradient(TRAIN_LOSS_WTS[1] * seg_loss, yolo_model.trainable_variables)\n",
    "            del pred_result,target\n",
    "            \n",
    "            if epoch > 0:\n",
    "                wts = yolo_model.trainable_variables\n",
    "                for i in conv_layer_ind:\n",
    "                        _wts = tf.abs(wts[i])\n",
    "                        vector = tf.reduce_sum(_wts,axis=[0,1])\n",
    "                        norm_rev_vec = 1 - vector/tf.reduce_max(vector)\n",
    "                        vec_dict[i] = norm_rev_vec\n",
    "                del wts, _wts\n",
    "                      \n",
    "            \n",
    "            for ind in range(len(gradients1)):\n",
    "                if type(gradients1[ind]) == type(None) : gradients1[ind] = 0.0\n",
    "                if type(gradients2[ind]) == type(None) : gradients2[ind] = 0.0\n",
    "                    \n",
    "                if ind in vec_dict.keys():\n",
    "                    gradients1[ind] = vec_dict[ind] * gradients1[ind] + gradients2[ind] * vec_dict[ind]\n",
    "                else:\n",
    "                    gradients1[ind] = gradients1[ind] + gradients2[ind]\n",
    "                    \n",
    "            optimizer.apply_gradients(zip(gradients1, yolo_model.trainable_variables))\n",
    "            \n",
    "            '''\n",
    "            global_steps.assign_add(1)\n",
    "            if global_steps < warmup_steps:# and not TRAIN_TRANSFER:\n",
    "                lr = global_steps / warmup_steps * TRAIN_LR_INIT\n",
    "            else:\n",
    "                lr = TRAIN_LR_END + 0.5 * (TRAIN_LR_INIT - TRAIN_LR_END)*(\n",
    "                    (1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
    "            optimizer.lr.assign(lr.numpy())\n",
    "            '''\n",
    "        return train_loss_dict, sample_loss_dict\n",
    "    \n",
    "def add_ext(loss_dict,_ext='val_'):\n",
    "    _loss_dict = {}\n",
    "    for key in loss_dict.keys():\n",
    "          _loss_dict[_ext+key]=loss_dict[key]\n",
    "    return _loss_dict\n",
    "\n",
    "@tf.function#(experimental_relax_shapes=True)\n",
    "def validate_step(image_data, target):\n",
    "    val_loss_dict = loss_dict_obj()\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = yolo_model(image_data)\n",
    "        del image_data\n",
    "        \n",
    "        grid = 3 if not TRAIN_YOLO_TINY else 2\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_dict, _, _ = calc_yolo_loss(pred, conv, *target[i], i)\n",
    "            loss_dict = add_ext(loss_dict,_ext='val_')\n",
    "            val_loss_dict.sum_update(loss_dict)\n",
    "        \n",
    "        if TRAIN_USE_SEG or TRAIN_USE_SEG_BIN:\n",
    "            seg_pred     = pred_result[2*(grid -1)+2:]\n",
    "            seg_label    = target[3:]\n",
    "            \n",
    "            loss_dict, _, _  = calc_seg_loss(seg_label,seg_pred)\n",
    "            loss_dict = add_ext(loss_dict,_ext='val_')\n",
    "            val_loss_dict.sum_update(loss_dict)\n",
    "            \n",
    "        del pred_result, target\n",
    "        \n",
    "    return val_loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940514fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Dataset('train')\n",
    "testset = Dataset('test')\n",
    "seg_utils = Seg_Utils()\n",
    "steps_per_epoch = len(trainset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64)\n",
    "warmup_steps = TRAIN_WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = TRAIN_EPOCHS * steps_per_epoch\n",
    "\n",
    "yolo = YoloModel(training=True)\n",
    "yolo_model =yolo.get_model()\n",
    "optimizer = tf.keras.optimizers.Adam(lr = TRAIN_LR)\n",
    "best_val_loss = 10e8 # should be large at start\n",
    "no_train_batch = trainset.num_batchs\n",
    "no_val_batch  = testset.num_batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7ba841",
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_gen == True:\n",
    "    for ind,[train_img, train_label] in tqdm(enumerate(trainset)):\n",
    "        path=TRAIN_DATA_SAVE_PATH+'batch_{}.npy'.format(str(ind))\n",
    "        np.save(path,[np.uint8(train_img*255.0),train_label[:3]]) \n",
    "        if TRAIN_USE_SEG:\n",
    "            path_seg=TRAIN_DATA_SAVE_PATH+'batch_seg_{}.npy'.format(str(ind))\n",
    "            train_label[3]  = tf.image.resize(train_label[3] ,(TRAIN_INPUT_SIZE//TRAIN_SEG_SCALE,TRAIN_INPUT_SIZE//TRAIN_SEG_SCALE),tf.image.ResizeMethod.BILINEAR).numpy()\n",
    "            no_obj = 1 - np.clip(train_label[3].max(axis=-1)[:,:,:,np.newaxis],0,1)\n",
    "            train_label[3] = np.concatenate([train_label[3],no_obj],axis = -1)\n",
    "            train_label[3] = np.argmax(train_label[3],axis = -1)\n",
    "            train_label[3] = np.array(train_label[3],dtype=np.uint8)\n",
    "            #train_label[3] = zlib.compress(train_label[3])\n",
    "            np.save(path_seg,train_label[3]) \n",
    "        #break\n",
    "    for ind,[test_img, test_label] in tqdm(enumerate(testset)):\n",
    "        path=TEST_DATA_SAVE_PATH+'batch_{}.npy'.format(str(ind))\n",
    "        np.save(path,[np.uint8(test_img*255.0),test_label[:3]])\n",
    "        if TRAIN_USE_SEG:\n",
    "            path_seg=TEST_DATA_SAVE_PATH+'batch_seg_{}.npy'.format(str(ind))\n",
    "            test_label[3] = tf.image.resize(test_label[3],(TEST_INPUT_SIZE//TRAIN_SEG_SCALE,TEST_INPUT_SIZE//TRAIN_SEG_SCALE),tf.image.ResizeMethod.BILINEAR).numpy()\n",
    "            no_obj = 1 - np.clip(test_label[3].max(axis=-1)[:,:,:,np.newaxis],0,1)\n",
    "            test_label[3] = np.concatenate([test_label[3],no_obj],axis = -1)\n",
    "            test_label[3] = np.argmax(test_label[3],axis = -1)\n",
    "            test_label[3] = np.array(test_label[3],dtype=np.uint8)\n",
    "            #test_label[3] = zlib.compress(test_label[3])\n",
    "            np.save(path_seg,test_label[3])\n",
    "        #break\n",
    "    del trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pp = tf.one_hot(tr_l[0][0],80)\n",
    "#plt.imshow(pp[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75f36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed23b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug == True:\n",
    "    no_train_batch = 3\n",
    "    no_val_batch   = 3\n",
    "    TRAIN_EPOCHS   = 100"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee0c8659",
   "metadata": {},
   "source": [
    "for batch_ind in tqdm(range(no_train_batch)):\n",
    "    path=TRAIN_DATA_SAVE_PATH+'batch_{}.npy'.format(str(batch_ind))\n",
    "    batch_data=np.load(path,allow_pickle=True)\n",
    "    if TRAIN_USE_SEG:\n",
    "        path=TRAIN_DATA_SAVE_PATH+'batch_seg_{}.npy'.format(str(batch_ind))\n",
    "        batch_seg=np.load(path,allow_pickle=True)\n",
    "        batch_seg = np.frombuffer(zlib.decompress(batch_seg),dtype=np.uint8).reshape(TRAIN_BATCH_SIZE,TRAIN_INPUT_SIZE,TRAIN_INPUT_SIZE,len(CLASS_NAMES))\n",
    "        batch_seg = [batch_seg]\n",
    "        \n",
    "    image_data, target = np.float32(batch_data[0]/255.0),list(batch_data[1])+batch_seg\n",
    "    pred = yolo_model.predict(image_data)\n",
    "    seg_loss = calc_seg_loss(pred[-1],target[3])\n",
    "    print(seg_loss)\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c6b95df",
   "metadata": {},
   "source": [
    "tboard_path = TRAIN_CHECKPOINTS_FOLDER+'TensorBoard/'\n",
    "if not os.path.exists(tboard_path): os.makedirs(tboard_path)\n",
    "tboard_callback = tf.keras.callbacks.TensorBoard(log_dir = tboard_path,\n",
    "                                                 histogram_freq = 1,\n",
    "                                                 profile_batch = '500,520')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4c628007",
   "metadata": {},
   "source": [
    "t1 = time.time()\n",
    "path=TRAIN_DATA_SAVE_PATH+'batch_seg_{}.npy'.format(str(0))\n",
    "batch_seg=np.load(path,allow_pickle=True)\n",
    "batch_dt= np.uint8(255*(batch_seg!=80))\n",
    "for i in range(len(batch_dt)):\n",
    "    batch_dt[i] = np.array(cv2.distanceTransform(batch_dt[i],cv2.DIST_L2,3),dtype=np.float32)\n",
    "print(t1-time.time())\n",
    "batch_dt = batch_dt/ np.sqrt(128**2 + 128**2)\n",
    "plt.imshow(batch_dt[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff4c93b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(TRAIN_CHECKPOINTS_FOLDER): os.makedirs(TRAIN_CHECKPOINTS_FOLDER)\n",
    "for epoch in range(TRAIN_EPOCHS):\n",
    "    all_logs = [] ; sample_losses =[]\n",
    "    train_loss_dict=loss_dict_obj(); val_loss_dict = loss_dict_obj(); loss_dict={'Epoch' : epoch}\n",
    "    #for image_data, target in tqdm(trainset):\n",
    "    batch_seg=[]\n",
    "    for batch_ind in tqdm(range(no_train_batch)):\n",
    "        path=TRAIN_DATA_SAVE_PATH+'batch_{}.npy'.format(str(batch_ind))\n",
    "        batch_data=np.load(path,allow_pickle=True)\n",
    "        if TRAIN_USE_SEG or TRAIN_USE_SEG_BIN:\n",
    "            path=TRAIN_DATA_SAVE_PATH+'batch_seg_{}.npy'.format(str(batch_ind))\n",
    "            batch_seg=np.load(path,allow_pickle=True)\n",
    "            batch_dt= np.uint8(255*(batch_seg!=80))\n",
    "            for i in range(len(batch_dt)):\n",
    "                batch_dt[i] = cv2.distanceTransform(batch_dt[i],cv2.DIST_L2,3)\n",
    "            batch_dt = np.float32(batch_dt/ np.sqrt(128**2 + 128**2))\n",
    "            \n",
    "        image_data, target = np.float32(batch_data[0]/255.0),list(batch_data[1])+[batch_seg,batch_dt]\n",
    "        train_loss , smp_loss = train_step(image_data, target,epoch)\n",
    "        del image_data, target\n",
    "        train_loss_dict.sum_update(train_loss)\n",
    "        all_logs+=[list(train_loss.values())]\n",
    "        \n",
    "        samp_l = []\n",
    "        for wt,loss_name in zip(TRAIN_LOSS_WTS,['det','seg']):\n",
    "            if wt : samp_l +=[smp_loss[loss_name]]\n",
    "        sample_losses +=[samp_l]\n",
    "        \n",
    "    train_loss_dict.divide(no_train_batch)\n",
    "    \n",
    "    iou_val, conf_val, prob_val, total_val = 0, 0, 0, 0\n",
    "    batch_seg=[]\n",
    "    #for image_data, target in testset:\n",
    "    for batch_ind in tqdm(range(no_val_batch)):\n",
    "        path=TEST_DATA_SAVE_PATH+'batch_{}.npy'.format(str(batch_ind))\n",
    "        batch_data=np.load(path,allow_pickle=True)\n",
    "        if TRAIN_USE_SEG or TRAIN_USE_SEG_BIN:\n",
    "            path=TEST_DATA_SAVE_PATH+'batch_seg_{}.npy'.format(str(batch_ind))\n",
    "            batch_seg=np.load(path,allow_pickle=True)\n",
    "            batch_dt= np.uint8(255*(batch_seg!=80))\n",
    "            for i in range(len(batch_dt)):\n",
    "                batch_dt[i] = cv2.distanceTransform(batch_dt[i],cv2.DIST_L2,3)\n",
    "            batch_dt = np.float32(batch_dt/ np.sqrt(128**2 + 128**2))\n",
    "            \n",
    "        image_data, target = np.float32(batch_data[0]/255.0),list(batch_data[1])+[batch_seg,batch_dt]\n",
    "        val_loss = validate_step(image_data, target)\n",
    "        del image_data, target\n",
    "        val_loss_dict.sum_update(val_loss)\n",
    "        \n",
    "    val_loss_dict.divide(no_val_batch)\n",
    "    loss_dict.update(train_loss_dict)\n",
    "    loss_dict.update(val_loss_dict)\n",
    "        \n",
    "    print(loss_dict)\n",
    "    \n",
    "    if epoch % TRAIN_SAVE_WEIGHTS_EVERY == 0:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, 'model'+\"_epoch_{}_val_det_loss_{}\".format(epoch,round(loss_dict['val_det_loss'],4)))\n",
    "        yolo_model.save_weights(save_directory+'/weights')\n",
    "    \n",
    "    if TRAIN_SAVE_BEST_ONLY and best_val_loss>loss_dict['val_det_loss']:\n",
    "        save_directory = os.path.join(TRAIN_CHECKPOINTS_FOLDER, 'model')\n",
    "        yolo_model.save_weights(save_directory+'/weights')\n",
    "        best_val_loss = loss_dict['val_det_loss']\n",
    "       \n",
    "    save_loss_logs(loss_dict,epoch)\n",
    "    save_std_logs(train_loss,all_logs,epoch)\n",
    "    save_sample_losses(sample_losses,epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277db671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#git remote add upstream https://github.com/user/repo\n",
    "#git pull upstream master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292afe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
